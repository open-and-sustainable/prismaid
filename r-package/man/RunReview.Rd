% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapper.R
\name{RunReview}
\alias{RunReview}
\title{Run Review}
\usage{
RunReview(input_string)
}
\arguments{
\item{input_string}{A string representing the input data.}
}
\value{
A string indicating the result of the review process.
}
\description{
The input data must be structured in a TOML format, consisting of several sections and parameters.
}
\details{
This function interfaces with a shared library to perform a review process on the input data.

\strong{[project]}
\itemize{
\item \code{name}: A string representing the project title. Example: "Use of LLM for systematic review".
\item \code{author}: The name of the project author. Example: "John Doe".
\item \code{version}: The version number for the project configuration. Example: "1.0".
}

\strong{[project.configuration]}
\itemize{
\item \code{input_directory}: The file path to the directory containing manuscripts to be reviewed. Example: "/path/to/txt/files".
\item \code{results_file_name}: The path and base name for saving results (file extension will be added automatically). Example: "/path/to/save/results".
\item \code{output_format}: The format for output results. Options: "csv" (default) or "json".
\item \code{log_level}: Determines logging verbosity:
\itemize{
\item \code{"low"}: Minimal logging (default).
\item \code{"medium"}: Logs to standard output.
\item \code{"high"}: Logs to a file (see user manual for details).
}
\item \code{duplication}: Runs model queries twice for debugging purposes. Options: "yes" or "no" (default).
\item \code{cot_justification}: Requests chain-of-thought justification from the model. Options: "yes" or "no" (default).
\item \code{summary}: Generates and saves summaries of manuscripts. Options: "yes" or "no" (default).
}

\strong{[project.llm]}
\itemize{
\item Configuration for LLMs, supporting multiple instances (llm.1, llm.2, etc.) for ensemble reviews.
\item Parameters for each LLM include:
\itemize{
\item \code{provider}: The LLM service provider. Options: "OpenAI", "GoogleAI", "Cohere", "Anthropic", "DeepSeek", or "Perplexity".
\item \code{api_key}: API key for the provider. If empty, environment variables will be checked.
\item \code{model}: Model name. Options vary by provider:
\itemize{
\item OpenAI: "gpt-5-nano", "gpt-5-mini", "gpt-5.2", "gpt-5.1", "gpt-5", "o4-mini", "o3-mini", "o3", "o1-mini", "o1", "gpt-4.1-nano", "gpt-4.1-mini", "gpt-4.1", "gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo", or "" (default for cost optimization).
\item GoogleAI: "gemini-3-flash-preview", "gemini-3-pro-preview", "gemini-2.5-flash-lite", "gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash-lite", "gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro", or "" (default for cost optimization).
\item Cohere: "command-a-reasoning-08-2025", "command-a-03-2025", "command-r-08-2024", "command-r7b-12-2024", "command-r-plus", "command-r", "command-light", "command", or "" (default for cost optimization).
\item Anthropic: "claude-4-5-haiku", "claude-4-5-sonnet", "claude-4-5-opus", "claude-4-0-opus", "claude-4-0-sonnet", "claude-3-7-sonnet", "claude-3-5-sonnet", "claude-3-5-haiku", "claude-3-opus", "claude-3-sonnet", "claude-3-haiku", or "" (default for cost optimization).
\item DeepSeek: "deepseek-chat", "deepseek-reasoner", or "" (default for cost optimization).
\item Perplexity: "sonar-deep-research", "sonar-reasoning-pro", "sonar-pro", "sonar", or "" (default for cost optimization).
}
\item \code{temperature}: Controls model randomness. Range: 0 to 1 (0 to 2 for GoogleAI). Lower values reduce randomness.
\item \code{tpm_limit}: Tokens per minute limit before delaying prompts. Default: 0 (no delay).
\item \code{rpm_limit}: Requests per minute limit before delaying prompts. Default: 0 (no delay).
}
}

\strong{[prompt]}
\itemize{
\item Defines the main components of the prompt for reviews.
\item \code{persona}: Optional text specifying the model's role. Example: "You are an experienced scientist...".
\item \code{task}: Required text framing the task for the model. Example: "Map the concepts discussed in a scientific paper...".
\item \code{expected_result}: Required text describing the expected output structure in JSON.
\item \code{definitions}: Optional text defining concepts to clarify instructions. Example: "'Interest rate' is defined as...".
\item \code{example}: Optional example to illustrate concepts.
\item \code{failsafe}: Specifies a fallback if the concepts cannot be identified. Example: "Respond with an empty '' value if concepts are unclear".
}

\strong{[review]}
\itemize{
\item Defines the keys and possible values in the JSON object for the review.
\item Example entries:
\itemize{
\item [review.1]: \code{key = "interest rate"}, \verb{values = [""]}
\item [review.2]: \code{key = "regression models"}, \verb{values = ["yes", "no"]}
\item [review.3]: \code{key = "geographical scale"}, \verb{values = ["world", "continent", "river basin"]}
}
}
}
\examples{
RunReview("example input")
}
