% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapper.R
\name{Screening}
\alias{Screening}
\title{Screen Manuscripts for Systematic Review}
\usage{
Screening(input_string)
}
\arguments{
\item{input_string}{A string containing the TOML configuration for screening.}
}
\value{
A string indicating the result of the screening process.
}
\description{
Processes a list of manuscripts applying multiple filters to identify which should be
excluded from a systematic review. Supports both rule-based and AI-assisted screening.
}
\details{
This function screens manuscripts to identify items for exclusion based on various criteria.

The input data must be structured in a TOML format with the following sections:

\strong{[project]}
\itemize{
\item \code{name}: Project title. Example: "Screening for climate change literature".
\item \code{author}: Name of the project author. Example: "Jane Smith".
\item \code{version}: Version number for the configuration. Example: "1.0".
\item \code{input_file}: Path to CSV/JSON file containing manuscripts to screen. Example: "/path/to/manuscripts.csv".
\item \code{output_file}: Path where screening results will be saved. Example: "/path/to/screening_results".
\item \code{text_column}: Name of column containing text or path to text files. Example: "abstract" or "text_file_path".
\item \code{identifier_column}: Column name for unique manuscript identifiers. Example: "doi" or "id".
\item \code{output_format}: Format for results. Options: "csv" or "json".
\item \code{log_level}: Logging verbosity. Options: "low", "medium", or "high".
}

\strong{[filters.deduplication]}
\itemize{
\item \code{enabled}: Whether to apply deduplication. Options: true or false.
\item \code{use_ai}: Use AI for semantic similarity detection. Options: true or false.
\item \code{compare_fields}: List of fields to compare. Example: \link{"title", "abstract", "doi"}.
}

\strong{[filters.language]}
\itemize{
\item \code{enabled}: Whether to filter by language. Options: true or false.
\item \code{accepted_languages}: List of accepted language codes. Example: \link{"en", "es", "fr"}.
\item \code{use_ai}: Use AI for language detection. Options: true or false.
}

\strong{[filters.article_type]}
\itemize{
\item \code{enabled}: Whether to filter by article type. Options: true or false.
\item \code{use_ai}: Use AI for article classification. Options: true or false.
\item \code{exclude_reviews}: Exclude review articles. Options: true or false.
\item \code{exclude_editorials}: Exclude editorial articles. Options: true or false.
\item \code{exclude_letters}: Exclude letters to editor. Options: true or false.
\item \code{exclude_theoretical}: Exclude theoretical papers. Options: true or false.
\item \code{exclude_empirical}: Exclude empirical studies. Options: true or false.
\item \code{exclude_methods}: Exclude methodology papers. Options: true or false.
\item \code{exclude_single_case}: Exclude single case studies. Options: true or false.
\item \code{exclude_sample}: Exclude sample-based studies. Options: true or false.
\item \code{include_types}: Specific article types to include. Example: \link{"research", "case_study"}.
}

\strong{[filters.topic_relevance]}
\itemize{
\item \code{enabled}: Whether to filter by topic relevance. Options: true or false.
\item \code{use_ai}: Use AI for relevance scoring. Options: true or false.
\item \code{topics}: List of topic descriptions. Example: \link{"climate change impacts", "adaptation strategies"}.
\item \code{min_score}: Minimum relevance score (0-1) to include. Example: 0.7.
\item \code{score_weights.keyword_match}: Weight for keyword matching (0-1). Example: 0.3.
\item \code{score_weights.concept_match}: Weight for concept matching (0-1). Example: 0.4.
\item \code{score_weights.field_relevance}: Weight for field relevance (0-1). Example: 0.3.
}

\strong{[filters.llm]} (Optional, required if any filter has \code{use_ai = true})
\itemize{
\item Configuration for AI models, supporting multiple instances (llm.1, llm.2, etc.).
\item Parameters for each LLM:
\itemize{
\item \code{provider}: LLM service provider. Options: "OpenAI", "GoogleAI", "Cohere", "Anthropic", "DeepSeek", or "Perplexity".
\item \code{api_key}: API key for the provider. If empty, environment variables will be checked.
\item \code{model}: Model name (see RunReview documentation for available models per provider).
\item \code{temperature}: Controls randomness (0-1, or 0-2 for GoogleAI).
\item \code{tpm_limit}: Tokens per minute limit. Default: 0 (no limit).
\item \code{rpm_limit}: Requests per minute limit. Default: 0 (no limit).
}
}
}
\examples{
\dontrun{
config <- '
[project]
name = "Climate Literature Screening"
author = "Research Team"
version = "1.0"
input_file = "/data/manuscripts.csv"
output_file = "/results/screening"
text_column = "abstract"
identifier_column = "doi"
output_format = "csv"
log_level = "medium"

[filters.deduplication]
enabled = true
use_ai = false
compare_fields = ["title", "doi"]

[filters.language]
enabled = true
accepted_languages = ["en"]
use_ai = false

[filters.article_type]
enabled = true
use_ai = false
exclude_reviews = true
exclude_editorials = true
'
Screening(config)
}
}
