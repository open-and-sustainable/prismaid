@article{page_prisma_2021,
	title = {The {PRISMA} 2020 statement: an updated guideline for reporting systematic reviews},
	volume = {10},
	issn = {2046-4053},
	shorttitle = {The {PRISMA} 2020 statement},
	url = {https://doi.org/10.1186/s13643-021-01626-4},
	doi = {10.1186/s13643-021-01626-4},
	number = {1},
	urldate = {2022-11-03},
	journal = {Systematic Reviews},
	author = {Page, Matthew J. and McKenzie, Joanne E. and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hróbjartsson, Asbjørn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and Mayo-Wilson, Evan and McDonald, Steve and McGuinness, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and Moher, David},
	month = mar,
	year = {2021},
	pages = {89},
}


@article{boero_ai-enhanced_2024,
	title = {An {AI}-{Enhanced} {Systematic} {Review} of {Climate} {Adaptation} {Costs}: {Approaches} and {Advancements}, 2010–2021},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2225-1154},
	shorttitle = {An {AI}-{Enhanced} {Systematic} {Review} of {Climate} {Adaptation} {Costs}},
	url = {https://www.mdpi.com/2225-1154/12/8/116},
	doi = {10.3390/cli12080116},
	abstract = {This study addresses the critical global challenge of climate adaptation by assessing the inadequacies in current methodologies for estimating adaptation costs. Broad assessments reveal a significant investment shortfall in adaptation strategies, highlighting the necessity for precise cost analysis to guide effective policy-making. By employing the PRISMA 2020 protocol and enhancing it with the prismAId tool, this review systematically analyzes the recent evolution of cost assessment methodologies using state-of-the-art generative AI. The AI-enhanced approach facilitates rapid and replicable research extensions. The analysis reveals a significant geographical and sectoral disparity in research on climate adaptation costs, with notable underrepresentation of crucial areas and sectors that are most vulnerable to climate impacts. The study also highlights a predominant reliance on secondary data and a lack of comprehensive uncertainty quantification in economic assessments, suggesting an urgent need for methodological enhancements. It concludes that extending analyses beyond merely verifying that benefits exceed costs is crucial for supporting effective climate adaptation. By assessing the profitability of adaptation investments, it becomes possible to prioritize these investments not only against similar interventions but also across the broader spectrum of public spending.},
	language = {en},
	number = {8},
	urldate = {2024-08-14},
	journal = {Climate},
	author = {Boero, Riccardo},
	month = aug,
	year = {2024},
	pages = {116},
}

@article{schiavo_prospero_2019,
	title = {{PROSPERO}: {An} {International} {Register} of {Systematic} {Review} {Protocols}},
	volume = {38},
	issn = {0276-3869, 1540-9597},
	shorttitle = {{PROSPERO}},
	url = {https://www.tandfonline.com/doi/full/10.1080/02763869.2019.1588072},
	doi = {10.1080/02763869.2019.1588072},
	abstract = {PROSPERO is an international database of systematic review protocols produced by the University of York’s Center for Research and Dissemination and funded by the National Institute for Health Research. It contains protocols of systematic reviews on health and social care, welfare, public health, education, crime, justice, and health-related international development. PROSPERO compiles a comprehensive listing of systematic review protocols in an attempt to avoid duplication of effort, reduce reporting bias, and promote transparency.},
	language = {en},
	number = {2},
	urldate = {2024-11-10},
	journal = {Medical Reference Services Quarterly},
	author = {Schiavo, Julie H.},
	month = apr,
	year = {2019},
	pages = {171--180},
}

@misc{boero_extended_2024,
	title = {An {Extended} {Introduction} to the `{prismAId}` {Tool}: {Open}-{Source} and {Open} {Science} {AI} for {Systematic} {Reviews}},
	shorttitle = {An {Extended} {Introduction} to the `{prismAId}` {Tool}},
	url = {https://osf.io/wh8qn},
	doi = {10.31222/osf.io/wh8qn},
	abstract = {`prismAId` is an open-source tool designed to streamline systematic literature reviews by leveraging generative AI models for information extraction. It offers an accessible, efficient, and replicable method for extracting and analyzing data from scientific literature, eliminating the need for coding expertise. Supporting various review protocols, including PRISMA 2020, `prismAId` is distributed across multiple platforms — Go, Python, Julia, R — and provides user-friendly binaries compatible with Windows, macOS, and Linux. The tool integrates with leading large language models (LLMs) such as OpenAI's GPT series, Google's Gemini, Cohere's Command, and Anthropic's Claude, ensuring comprehensive and up-to-date literature analysis. `prismAId` facilitates systematic reviews, enabling researchers to conduct thorough, fast, and reproducible analyses, thereby advancing open science initiatives.},
	language = {en-us},
	urldate = {2024-12-05},
	publisher = {MetaArXiv},
	author = {Boero, Riccardo},
	month = nov,
	year = {2024},
	keywords = {Generative AI, Large Language Model, Open Source, Systematic Literature Review, Open Science},
}

@inproceedings{liu_autoie_2024,
	address = {Singapore},
	title = {{AutoIE}: {An} {Automated} {Framework} for {Information} {Extraction} from {Scientific} {Literature}},
	isbn = {978-981-97-5495-3},
	shorttitle = {{AutoIE}},
	doi = {10.1007/978-981-97-5495-3_32},
	abstract = {In the rapidly evolving field of scientific research, efficiently extracting key information from the burgeoning volume of scientific papers remains a formidable challenge. This paper introduces an innovative framework designed to automate the extraction of vital data from scientific PDF documents, enabling researchers to discern future research trajectories more readily. AutoIE uniquely integrates four novel components: (1) A multi-semantic feature fusion-based approach for PDF document layout analysis; (2) Advanced functional block recognition in scientific texts; (3) A synergistic technique for extracting and correlating information on molecular sieve synthesis; (4) An online learning paradigm tailored for molecular sieve literature. Our SBERT model achieves high Marco F1 scores of 87.19 and 89.65 on CoNLL04 and ADE datasets. In addition, a practical application of AutoIE in the petrochemical molecular sieve synthesis domain demonstrates its efficacy, evidenced by an impressive 78\% accuracy rate. This research paves the way for enhanced data management and interpretation in molecular sieve synthesis. It is a valuable asset for seasoned experts and newcomers in this specialized field.},
	language = {en},
	booktitle = {Knowledge {Science}, {Engineering} and {Management}},
	publisher = {Springer Nature},
	author = {Liu, Yangyang and Li, Shoubin and Huang, Kai and Wang, Qing},
	editor = {Cao, Cungeng and Chen, Huajun and Zhao, Liang and Arshad, Junaid and Asyhari, Taufiq and Wang, Yonghao},
	year = {2024},
	pages = {424--436},
}

@misc{donoghue_lisc_2019,
	title = {{LISC}: {A} {Python} {Package} for {Scientific} {Literature} {Collection} and {Analysis}},
	copyright = {Apache-2.0},
	shorttitle = {{LISC}},
	url = {https://github.com/lisc-tools/lisc},
	abstract = {Literature Scanner: Automated collection \& analyses of the scientific literature.},
	urldate = {2025-01-02},
	author = {Donoghue, Thomas},
	year = {2019},
	doi = {10.21105/joss.01674},
	note = {Issue: 41
Pages: 1674
Publication Title: Journal of Open Source Software
Volume: 4
original-date: 2018-06-20T03:45:47Z},
}

@article{mahadevkar_exploring_2024,
	title = {Exploring {AI}-driven approaches for unstructured document analysis and future horizons},
	volume = {11},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-024-00948-z},
	doi = {10.1186/s40537-024-00948-z},
	abstract = {In the current industrial landscape, a significant number of sectors are grappling with the challenges posed by unstructured data, which incurs financial losses amounting to millions annually. If harnessed effectively, this data has the potential to substantially boost operational efficiency. Traditional methods for extracting information have their limitations; however, solutions powered by artificial intelligence (AI) could provide a more fitting alternative. There is an evident gap in scholarly research concerning a comprehensive evaluation of AI-driven techniques for the extraction of information from unstructured content. This systematic literature review aims to identify, assess, and deliberate on prospective research directions within the field of unstructured document information extraction. It has been observed that prevailing extraction methods primarily depend on static patterns or rules, often proving inadequate when faced with complex document structures typically encountered in real-world scenarios, such as medical records. Datasets currently available to the public suffer from low quality and are tailored for specific tasks only. This underscores an urgent need for developing new datasets that accurately reflect complex issues encountered in practical settings. The review reveals that AI-based techniques show promise in autonomously extracting information from diverse unstructured documents, encompassing both printed and handwritten text. Challenges arise, however, when dealing with varied document layouts. Proposing a framework through hybrid AI-based approaches, this review envisions processing a high-quality dataset for automatic information extraction from unstructured documents. Additionally, it emphasizes the importance of collaborative efforts between organizations and researchers to address the diverse challenges associated with unstructured data analysis.},
	number = {1},
	urldate = {2025-01-02},
	journal = {Journal of Big Data},
	author = {Mahadevkar, Supriya V. and Patil, Shruti and Kotecha, Ketan and Soong, Lim Way and Choudhury, Tanupriya},
	month = jul,
	year = {2024},
	keywords = {Artificial intelligence, Information extraction, Large Language models, Named entity recognition, Optical character recognition, Printed and handwritten text recognition, Robotics process automation, Semantic segmentation, Unstructured document processing},
	pages = {92},
}

@article{abdullah_systematic_2023,
	title = {Systematic {Literature} {Review} of {Information} {Extraction} {From} {Textual} {Data}: {Recent} {Methods}, {Applications}, {Trends}, and {Challenges}},
	volume = {11},
	issn = {2169-3536},
	shorttitle = {Systematic {Literature} {Review} of {Information} {Extraction} {From} {Textual} {Data}},
	url = {https://ieeexplore.ieee.org/document/10032132},
	doi = {10.1109/ACCESS.2023.3240898},
	abstract = {Information extraction (IE) is a challenging task, particularly when dealing with highly heterogeneous data. State-of-the-art data mining technologies struggle to process information from textual data. Therefore, various IE techniques have been developed to enable the use of IE for textual data. However, each technique differs from one another because it is designed for different data types and has different target information to be extracted. This study investigated and described the most contemporary methods for extracting information from textual data, emphasizing their benefits and shortcomings. To provide a holistic view of the domain, this comprehensive systematic literature review employed a systematic mapping process to summarize studies published in the last six years (from 2017 to 2022). It covers fundamental concepts, recent approaches, applications, and trends, in addition to challenges and future research prospects in this domain area. Based on an analysis of 161 selected studies, we found that the state-of-the-art models employ deep learning to extract information from textual data. Finally, this study aimed to guide novice and experienced researchers in future research and serve as a foundation for this research area.},
	urldate = {2025-01-02},
	journal = {IEEE Access},
	author = {Abdullah, Mohd Hafizul Afifi and Aziz, Norshakirah and Abdulkadir, Said Jadid and Alhussian, Hitham Seddig Alhassan and Talpur, Noureen},
	year = {2023},
	note = {Conference Name: IEEE Access},
	keywords = {Analytical models, Data mining, deep learning, event extraction, Feature extraction, Hidden Markov models, Information extraction, Market research, named entity, named entity recognition, relation extraction, Systematics, Task analysis, text extraction},
	pages = {10535--10562},
}

@article{van_dinter_automation_2021,
	title = {Automation of systematic literature reviews: {A} systematic literature review},
	volume = {136},
	issn = {0950-5849},
	shorttitle = {Automation of systematic literature reviews},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921000690},
	doi = {10.1016/j.infsof.2021.106589},
	abstract = {Context
Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as software engineering, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a systematic overview of the current state-of-the-art in SLR automation seems to be lacking.
Objective
This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research.
Method
A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed.
Results
This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions.
Conclusion
According to our study, the leading automated step is the Selection of Primary Studies. Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process.},
	urldate = {2025-01-02},
	journal = {Information and Software Technology},
	author = {van Dinter, Raymon and Tekinerdogan, Bedir and Catal, Cagatay},
	month = aug,
	year = {2021},
	keywords = {Automation, Machine learning, Natural language processing, Review, Systematic literature review (SLR), Text mining},
	pages = {106589},
}

@article{kiritchenko_exact_2010,
	title = {{ExaCT}: automatic extraction of clinical trial characteristics from journal publications},
	volume = {10},
	issn = {1472-6947},
	shorttitle = {{ExaCT}},
	url = {https://doi.org/10.1186/1472-6947-10-56},
	doi = {10.1186/1472-6947-10-56},
	abstract = {Clinical trials are one of the most important sources of evidence for guiding evidence-based practice and the design of new trials. However, most of this information is available only in free text - e.g., in journal publications - which is labour intensive to process for systematic reviews, meta-analyses, and other evidence synthesis studies. This paper presents an automatic information extraction system, called ExaCT, that assists users with locating and extracting key trial characteristics (e.g., eligibility criteria, sample size, drug dosage, primary outcomes) from full-text journal articles reporting on randomized controlled trials (RCTs).},
	number = {1},
	urldate = {2025-01-02},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Kiritchenko, Svetlana and de Bruijn, Berry and Carini, Simona and Martin, Joel and Sim, Ida},
	month = sep,
	year = {2010},
	keywords = {Extraction Rule, Information Element, Information Extraction, Target Information, Text Fragment},
	pages = {56},
}

@article{saldanha_evaluating_2016,
	title = {Evaluating {Data} {Abstraction} {Assistant}, a novel software application for data abstraction during systematic reviews: protocol for a randomized controlled trial},
	volume = {5},
	issn = {2046-4053},
	shorttitle = {Evaluating {Data} {Abstraction} {Assistant}, a novel software application for data abstraction during systematic reviews},
	url = {https://doi.org/10.1186/s13643-016-0373-7},
	doi = {10.1186/s13643-016-0373-7},
	abstract = {Data abstraction, a critical systematic review step, is time-consuming and prone to errors. Current standards for approaches to data abstraction rest on a weak evidence base. We developed the Data Abstraction Assistant (DAA), a novel software application designed to facilitate the abstraction process by allowing users to (1) view study article PDFs juxtaposed to electronic data abstraction forms linked to a data abstraction system, (2) highlight (or “pin”) the location of the text in the PDF, and (3) copy relevant text from the PDF into the form. We describe the design of a randomized controlled trial (RCT) that compares the relative effectiveness of (A) DAA-facilitated single abstraction plus verification by a second person, (B) traditional (non-DAA-facilitated) single abstraction plus verification by a second person, and (C) traditional independent dual abstraction plus adjudication to ascertain the accuracy and efficiency of abstraction.},
	number = {1},
	urldate = {2025-01-02},
	journal = {Systematic Reviews},
	author = {Saldanha, Ian J. and Schmid, Christopher H. and Lau, Joseph and Dickersin, Kay and Berlin, Jesse A. and Jap, Jens and Smith, Bryant T. and Carini, Simona and Chan, Wiley and De Bruijn, Berry and Wallace, Byron C. and Hutfless, Susan M. and Sim, Ida and Murad, M. Hassan and Walsh, Sandra A. and Whamond, Elizabeth J. and Li, Tianjing},
	month = nov,
	year = {2016},
	keywords = {Data abstraction, Randomized controlled trial, Systematic reviews},
	pages = {196},
}

@misc{distiller_SR,
	title = {Systematic {Review} and {Literature} {Review} {Software} by {DistillerSR}},
	author={DistillerSR},
	url = {https://www.distillersr.com/},
	abstract = {DistillerSR automates every stage of your literature reviews to produce evidence-based research faster and more accurately.},
	language = {en-US},
	urldate = {2025-01-02},
	date={2025},
}

@article{schopow_applications_2023,
	title = {Applications of the {Natural} {Language} {Processing} {Tool} {ChatGPT} in {Clinical} {Practice}: {Comparative} {Study} and {Augmented} {Systematic} {Review}},
	volume = {11},
	copyright = {This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published JMIR Medical Informatics, is properly cited. The complete bibliographic information, a link to the original publication on https://medinform.jmir.org/, as well as this copyright and license information must be included.},
	shorttitle = {Applications of the {Natural} {Language} {Processing} {Tool} {ChatGPT} in {Clinical} {Practice}},
	url = {https://medinform.jmir.org/2023/1/e48933},
	doi = {10.2196/48933},
	abstract = {Background: This research integrates a comparative analysis of the performance of human researchers and OpenAI's ChatGPT in systematic review tasks and describes an assessment of the application of natural language processing (NLP) models in clinical practice through a review of 5 studies.
Objective: This study aimed to evaluate the reliability between ChatGPT and human researchers in extracting key information from clinical articles, and to investigate the practical use of NLP in clinical settings as evidenced by selected studies.
Methods: The study design comprised a systematic review of clinical articles executed independently by human researchers and ChatGPT. The level of agreement between and within raters for parameter extraction was assessed using the Fleiss and Cohen κ statistics.
Results: The comparative analysis revealed a high degree of concordance between ChatGPT and human researchers for most parameters, with less agreement for study design, clinical task, and clinical implementation. The review identified 5 significant studies that demonstrated the diverse applications of NLP in clinical settings. These studies’ findings highlight the potential of NLP to improve clinical efficiency and patient outcomes in various contexts, from enhancing allergy detection and classification to improving quality metrics in psychotherapy treatments for veterans with posttraumatic stress disorder.
Conclusions: Our findings underscore the potential of NLP models, including ChatGPT, in performing systematic reviews and other clinical tasks. Despite certain limitations, NLP models present a promising avenue for enhancing health care efficiency and accuracy. Future studies must focus on broadening the range of clinical applications and exploring the ethical considerations of implementing NLP applications in health care settings.},
	language = {EN},
	number = {1},
	urldate = {2025-01-02},
	journal = {JMIR Medical Informatics},
	author = {Schopow, Nikolas and Osterhoff, Georg and Baur, David},
	month = nov,
	year = {2023},
	note = {Company: JMIR Medical Informatics
Distributor: JMIR Medical Informatics
Institution: JMIR Medical Informatics
Label: JMIR Medical Informatics
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e48933},
}

@article{khalil_tools_2022,
	title = {Tools to support the automation of systematic reviews: a scoping review},
	volume = {144},
	issn = {0895-4356},
	shorttitle = {Tools to support the automation of systematic reviews},
	url = {https://www.sciencedirect.com/science/article/pii/S0895435621004029},
	doi = {10.1016/j.jclinepi.2021.12.005},
	abstract = {Objective
The objectives of this scoping review are to identify the reliability and validity of the available tools, their limitations and any recommendations to further improve the use of these tools.
Study design
A scoping review methodology was followed to map the literature published on the challenges and solutions of conducting evidence synthesis using the JBI scoping review methodology.
Results
A total of 47 publications were included in the review. The current scoping review identified that LitSuggest, Rayyan, Abstractr, BIBOT, R software, RobotAnalyst, DistillerSR, ExaCT and NetMetaXL have potential to be used for the automation of systematic reviews. However, they are not without limitations. The review also identified other studies that employed algorithms that have not yet been developed into user friendly tools. Some of these algorithms showed high validity and reliability but their use is conditional on user knowledge of computer science and algorithms.
Conclusion
Abstract screening has reached maturity; data extraction is still an active area. Developing methods to semi-automate different steps of evidence synthesis via machine learning remains an important research direction. Also, it is important to move from the research prototypes currently available to professionally maintained platforms.},
	urldate = {2025-01-02},
	journal = {Journal of Clinical Epidemiology},
	author = {Khalil, Hanan and Ameen, Daniel and Zarnegar, Armita},
	month = apr,
	year = {2022},
	keywords = {Abstract screening, Artificial intelligence, Automation, Machine learning, Reliability, Systematic review},
	pages = {22--42},
}

@article{affengruber_exploration_2024,
	title = {An exploration of available methods and tools to improve the efficiency of systematic review production: a scoping review},
	volume = {24},
	issn = {1471-2288},
	shorttitle = {An exploration of available methods and tools to improve the efficiency of systematic review production},
	url = {https://doi.org/10.1186/s12874-024-02320-4},
	doi = {10.1186/s12874-024-02320-4},
	abstract = {Systematic reviews (SRs) are time-consuming and labor-intensive to perform. With the growing number of scientific publications, the SR development process becomes even more laborious. This is problematic because timely SR evidence is essential for decision-making in evidence-based healthcare and policymaking. Numerous methods and tools that accelerate SR development have recently emerged. To date, no scoping review has been conducted to provide a comprehensive summary of methods and ready-to-use tools to improve efficiency in SR production.},
	number = {1},
	urldate = {2025-01-02},
	journal = {BMC Medical Research Methodology},
	author = {Affengruber, Lisa and van der Maten, Miriam M. and Spiero, Isa and Nussbaumer-Streit, Barbara and Mahmić-Kaknjo, Mersiha and Ellen, Moriah E. and Goossen, Käthe and Kantorova, Lucia and Hooft, Lotty and Riva, Nicoletta and Poulentzas, Georgios and Lalagkas, Panagiotis Nikolaos and Silva, Anabela G. and Sassano, Michele and Sfetcu, Raluca and Marqués, María E. and Friessova, Tereza and Baladia, Eduard and Pezzullo, Angelo Maria and Martinez, Patricia and Gartlehner, Gerald and Spijker, René},
	month = sep,
	year = {2024},
	keywords = {Automation tools, Evidence synthesis, Method, Rapid review, Scoping review, Systematic review},
	pages = {210},
}

@article{alshami_harnessing_2023,
	title = {Harnessing the {Power} of {ChatGPT} for {Automating} {Systematic} {Review} {Process}: {Methodology}, {Case} {Study}, {Limitations}, and {Future} {Directions}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-8954},
	shorttitle = {Harnessing the {Power} of {ChatGPT} for {Automating} {Systematic} {Review} {Process}},
	url = {https://www.mdpi.com/2079-8954/11/7/351},
	doi = {10.3390/systems11070351},
	abstract = {Systematic reviews (SR) are crucial in synthesizing and analyzing existing scientific literature to inform evidence-based decision-making. However, traditional SR methods often have limitations, including a lack of automation and decision support, resulting in time-consuming and error-prone reviews. To address these limitations and drive the field forward, we harness the power of the revolutionary language model, ChatGPT, which has demonstrated remarkable capabilities in various scientific writing tasks. By utilizing ChatGPT’s natural language processing abilities, our objective is to automate and streamline the steps involved in traditional SR, explicitly focusing on literature search, screening, data extraction, and content analysis. Therefore, our methodology comprises four modules: (1) Preparation of Boolean research terms and article collection, (2) Abstract screening and articles categorization, (3) Full-text filtering and information extraction, and (4) Content analysis to identify trends, challenges, gaps, and proposed solutions. Throughout each step, our focus has been on providing quantitative analyses to strengthen the robustness of the review process. To illustrate the practical application of our method, we have chosen the topic of IoT applications in water and wastewater management and quality monitoring due to its critical importance and the dearth of comprehensive reviews in this field. The findings demonstrate the potential of ChatGPT in bridging the gap between traditional SR methods and AI language models, resulting in enhanced efficiency and reliability of SR processes. Notably, ChatGPT exhibits exceptional performance in filtering and categorizing relevant articles, leading to significant time and effort savings. Our quantitative assessment reveals the following: (1) the overall accuracy of ChatGPT for article discarding and classification is 88\%, and (2) the F-1 scores of ChatGPT for article discarding and classification are 91\% and 88\%, respectively, compared to expert assessments. However, we identify limitations in its suitability for article extraction. Overall, this research contributes valuable insights to the field of SR, empowering researchers to conduct more comprehensive and reliable reviews while advancing knowledge and decision-making across various domains.},
	language = {en},
	number = {7},
	urldate = {2025-01-02},
	journal = {Systems},
	author = {Alshami, Ahmad and Elsayed, Moustafa and Ali, Eslam and Eltoukhy, Abdelrahman E. E. and Zayed, Tarek},
	month = jul,
	year = {2023},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {article categorization, article filtration, automation, ChatGPT, content analysis, information extraction, Internet of Things (IoT), systematic review},
	pages = {351},
}

@misc{prismaid-doc,
  author = {Boero, Riccardo},
  title = {{prismAId - Documentation website}},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub pages},
  url = {https://open-and-sustainable.github.io/prismaid/}
}
